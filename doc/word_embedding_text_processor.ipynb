{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word embedding text processor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML0u2NgXyXYA",
        "colab_type": "text"
      },
      "source": [
        "# Text processor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDkoNHGgdosA",
        "colab_type": "text"
      },
      "source": [
        "###Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANgKSl4yZ8RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import psycopg2\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import html\n",
        "import spacy\n",
        "from pathlib import Path\n",
        "import collections\n",
        "import datetime as dt\n",
        "import pickle\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaM2ZoLFXPVf",
        "colab_type": "text"
      },
      "source": [
        "#### Import ulangel library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7jHSFdtXRuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ulangel.data.text_processor import text_proc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2hMhQZqeFee",
        "colab_type": "text"
      },
      "source": [
        "### Import your text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3s1oSbeIOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df = pd.read_csv('your text path')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqBBJmG6GhKk",
        "colab_type": "text"
      },
      "source": [
        "#### If necessary, combine columns to make the whole text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk8xSa_dGqyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_txt(df):\n",
        "    return '<Author> ' + df.author + ' <Title> ' + df.title + ' <Description> ' + df.description"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRCTFkAnTyRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df['text'] = get_txt(text_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cHc4l9VT3MG",
        "colab_type": "text"
      },
      "source": [
        "### text processor\n",
        "In the **text_proc** method of ulangel.data.text_processor, here are the processing steps:\n",
        "1. Replace HTML special characters and emoji\n",
        "2. Replace word repetitions and add `xxwrep` ahead: word word word -> xxwrep 3 word\n",
        "3. Replace character repetitions and add `xxrep` ahead: cccc -> xxrep 4 c\n",
        "4. Add spaces around /,@,#,:\n",
        "5. Remove multiple spaces and keep just one\n",
        "6. Tokenize the text\n",
        "7. Replace tokens with all letters in capitals by their lower case and add `xxup` ahead: GOOD JOB -> xxup good xxup job\n",
        "8. Replace tokens with the first letter in capital by their lower caser and add `xxmaj` ahead: We -> xxmaj we\n",
        "9. Add `xbos` at the beginning and `xfld` at the end of the text\n",
        "\n",
        "The method **get_all** applies **text_proc** line by line an return a list of lists of tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBFTsQFFdFU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all(df):\n",
        "    tok = []\n",
        "    time_begin = dt.datetime.now()\n",
        "    time_boucle = time_begin\n",
        "    tokenizer = spacy.load('en').tokenizer\n",
        "    for i, r in df.iterrows(): \n",
        "        text = r['text']\n",
        "        tok_ = text_proc(text, tokenizer)\n",
        "        tok += tok_\n",
        "        if i%5000==0:\n",
        "            time_end = dt.datetime.now()\n",
        "            print('Time for 5000 lines: ' + str(time_end - time_boucle))\n",
        "            time_boucle = time_end\n",
        "    time_end = dt.datetime.now()\n",
        "    print('Total Time: ' + str(time_end - time_begin))\n",
        "    return tok"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYfEZD6x3Nfo",
        "colab_type": "text"
      },
      "source": [
        "#### apply text processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPcaoZaMdaY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok_lm = get_all(text_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KotnPQi2f053",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df['tok'] = tok_lm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD57hT7dgsoH",
        "colab_type": "text"
      },
      "source": [
        "### Create the dictionary itos (integer to string) of the corpus and the inverse dictionary stoi (string to integer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4s6m7RUhODq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq = collections.Counter(p for o in text_df['tok'].values for p in o)\n",
        "# define the maximum size of the dictionary\n",
        "max_vocab = 60000\n",
        "# define the minimum of appearance of the word to be inclued into the dictionary\n",
        "min_freq = 100\n",
        "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
        "itos.insert(0, '_pad_')\n",
        "itos.insert(0, '_unk_')\n",
        "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twBSa8yjiJyG",
        "colab_type": "text"
      },
      "source": [
        "### Save the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Ig4fWCiNUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(itos, open('../itos.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0o0IOLbibJN",
        "colab_type": "text"
      },
      "source": [
        "### Word(Token) Numeralization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obvNc8b7iQpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_df['ids'] = text_df['tok'].apply(lambda toks: [stoi[t] for t in toks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gal1KAHxbuh",
        "colab_type": "text"
      },
      "source": [
        "### Labels Numeralization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2FAU__lxbUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_labels(df):\n",
        "    df['type_nb'] = 0\n",
        "    for i, row in df.iterrows():\n",
        "        if row['label'] == 'cat1':\n",
        "            df.at[i, 'type_nb'] = 0\n",
        "        elif row['label'] == 'cat2':\n",
        "            df.at[i, 'type_nb'] = 1\n",
        "        elif row['label'] == 'cat3':\n",
        "            df.at[i, 'type_nb'] = 2\n",
        "        elif row['label'] == 'cat4':\n",
        "            df.at[i, 'type_nb'] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc_dqoaBxnTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels(text_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia77Sz7-gCv-",
        "colab_type": "text"
      },
      "source": [
        "### Devide data into training set and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EIOGS_f-6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_lm, val_lm = sklearn.model_selection.train_test_split(text_df, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr3hwk6_gghH",
        "colab_type": "text"
      },
      "source": [
        "### Save datasets into json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoZ7yCLtgK_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_lm_J = json.loads(trn_lm.to_json(orient='index'))\n",
        "with open('../trn_lm_tok.json', 'w') as f:\n",
        "    json.dump(trn_lm_J, f, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWs65W7ugpa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_lm_J = json.loads(val_lm.to_json(orient='index'))\n",
        "with open('../val_lm_tok.json', 'w') as f:\n",
        "    json.dump(val_lm_J, f, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTDp4ufygzUt",
        "colab_type": "text"
      },
      "source": [
        "### Save tokens into npy files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLLzpcIQgusE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('../trn_lm_tok.npy', trn_lm['tok'].values)\n",
        "np.save('../val_lm_tok.npy', val_lm['tok'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjogESbFwvin",
        "colab_type": "text"
      },
      "source": [
        "### Save indexes into npy files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPjceZO9wuso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('../trn_lm_ids.npy', trn_lm['ids'].values)\n",
        "np.save('../val_lm_ids.npy', val_lm['ids'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGnJyyO6xrxz",
        "colab_type": "text"
      },
      "source": [
        "### Save labels into npy files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSp8MUClxrKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('../trn_lm_labels.npy', trn_lm['type_nb'].values)\n",
        "np.save('../val_lm_labels.npy', val_lm['type_nb'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAHV90C7yNNZ",
        "colab_type": "text"
      },
      "source": [
        "# Match our itos to the pretrained wt103 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ganwJwW0zIjG",
        "colab_type": "text"
      },
      "source": [
        "### get the pretrained model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQtPhdI9yMjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wgts = torch.load('../wt103/fwd_wt103.h5') # , map_location='cpu' if on a cpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6Q-7lAfynCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../wt103/itos_wt103.pkl', 'rb') as f:\n",
        "    itos_wt103 = pickle.load(f)\n",
        "stoi_wt103 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos_wt103)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91nCUutTzL2M",
        "colab_type": "text"
      },
      "source": [
        "### define the size of our own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzlcfYeDyzjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vs = len(itos)\n",
        "em_sz = 400\n",
        "nh = 1150\n",
        "nl = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg5GbTM1zYA5",
        "colab_type": "text"
      },
      "source": [
        "### Corresponding the pretrained wt103 model to our own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8L5p5ry1ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_wgts = wgts['0.encoder.weight'].numpy()\n",
        "row_m = enc_wgts.mean(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfmPEMV3y5dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
        "for i,w in enumerate(itos):\n",
        "    r = stoi_wt103[w]\n",
        "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YSV11ufy9QY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wgts['0.encoder.weight'] = torch.FloatTensor(new_w)\n",
        "wgts['0.encoder_with_dropout.embed.weight'] = torch.FloatTensor(np.copy(new_w))\n",
        "wgts['1.decoder.weight'] = torch.FloatTensor(np.copy(new_w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E10nZZ3sy_DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(wgts, '../model_after_corresponding.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
