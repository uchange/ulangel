{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "freeze_to.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKrC4CALOuKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxLDwdNsOwkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = Path('/content/drive/My Drive/cse_class_train/word_emb')\n",
        "CLAS_PATH = Path('/content/drive/My Drive/cse_class_train/word_emb/classifier')\n",
        "LM_PATH = Path('/content/drive/My Drive/cse_class_train/word_emb/language_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYqGpyvPHRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ulangel.data.data_packer import LanguageModelDataset, DataBunch, TextClassificationDataset\n",
        "from ulangel.data.data_packer import ValidationSampler, TrainingSampler, pad_collate\n",
        "from ulangel.rnn.nn_block import AWD_LSTM, LinearDecoder, SequentialRNN, SentenceEncoder\n",
        "from ulangel.rnn.nn_block import PoolingLinearClassifier\n",
        "from ulangel.utils.callbacks import TrainEvalCallback, CudaCallback, Recorder, LR_Find\n",
        "from ulangel.utils.callbacks import RNNTrainer, combine_scheds, ParamScheduler, sched_cos\n",
        "from ulangel.utils.learner import Learner, freeze_all, unfreeze_all, freeze_upto\n",
        "from ulangel.utils.optimizer import Optimizer, StatefulOptimizer, AverageGrad, AverageSqrGrad\n",
        "from ulangel.utils.optimizer import adam_opt\n",
        "from ulangel.utils.stats import AvgStatsCallback, accuracy, accuracy_flat, cross_entropy_flat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx-iC9ksPmXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_lm = np.load(LM_PATH/'trn_lm_ids.npy', allow_pickle=True)\n",
        "val_lm = np.load(LM_PATH/'val_lm_ids.npy', allow_pickle=True)\n",
        "\n",
        "trn_dl = DataLoader(LanguageModelDataset(trn_lm, bptt=16), batch_size=64)\n",
        "val_dl = DataLoader(LanguageModelDataset(val_lm, bptt=16), batch_size=64*2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LDSNeM9PpTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language_model_data = DataBunch(trn_dl, val_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2AUsGaxPscH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LmArg:\n",
        "    def __init__(self):\n",
        "        self.ntokens = 15484\n",
        "        self.batchsize = 64\n",
        "        self.emsize = 400\n",
        "        self.pad_token = 1\n",
        "        self.emb_drop = 0.05\n",
        "        # number of activation in hidden layer\n",
        "        self.nhid = 1150\n",
        "        self.nlayers = 3\n",
        "        # decoder dropout\n",
        "        self.dropout = 0.4\n",
        "        # dropout for rnn layers\n",
        "        self.dropouth = 0.3\n",
        "        # dropout for input embedding layers\n",
        "        self.dropouti = 0.65\n",
        "        # dropout to remove words from embedding layer\n",
        "        self.dropoute = 0.1\n",
        "        # amount of weight dropout to apply to the RNN hidden to hidden matrix\n",
        "        self.wdrop = 0.5\n",
        "        self.tied = False\n",
        "        self.bidir = False\n",
        "        # recurrent dropout of lstm (from t to t+1)\n",
        "        self.lstm_weights_drop = 0.5\n",
        "        self.cuda = torch.cuda.is_available()\n",
        "        self.bptt = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-7CNIXPtfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encode_args = LmArg()\n",
        "lstm_enc = AWD_LSTM(\n",
        "    encode_args.ntokens, encode_args.emsize, encode_args.nhid,\n",
        "    encode_args.nlayers, encode_args.pad_token,\n",
        "    encode_args.dropouth, encode_args.dropouti, encode_args.dropoute,\n",
        "    encode_args.wdrop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Md5K9QPtGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = LinearDecoder(\n",
        "    encode_args.ntokens, encode_args.emsize, encode_args.dropout, tie_encoder=lstm_enc.emb, bias=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7iCrheqP4Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language_model = SequentialRNN(lstm_enc, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnq-7nyQP8H5",
        "colab_type": "code",
        "outputId": "7d0ca503-b35b-41a0-aa3d-415e7907f64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "source": [
        "language_model.modules"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.modules of SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (emb): Embedding(15484, 400, padding_idx=1)\n",
              "    (emb_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(15484, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): ConnectionWeightDropout(\n",
              "        (module): LSTM(400, 1150, batch_first=True)\n",
              "      )\n",
              "      (1): ConnectionWeightDropout(\n",
              "        (module): LSTM(1150, 1150, batch_first=True)\n",
              "      )\n",
              "      (2): ConnectionWeightDropout(\n",
              "        (module): LSTM(1150, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): ActivationDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): ActivationDropout()\n",
              "      (1): ActivationDropout()\n",
              "      (2): ActivationDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (output_dp): ActivationDropout()\n",
              "    (decoder): Linear(in_features=400, out_features=15484, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYbm4VAoQDZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbs_languagemodel = [\n",
        "    CudaCallback(), TrainEvalCallback(), AvgStatsCallback([accuracy_flat]),\n",
        "    Recorder(), RNNTrainer(alpha=2., beta=1.)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_132by7O_B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language_model_learner = Learner(\n",
        "      model=language_model,\n",
        "      data=language_model_data,\n",
        "      loss_func=cross_entropy_flat,\n",
        "      opt_func=adam_opt(),\n",
        "      lr=1e-5,\n",
        "      cbs=cbs_languagemodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bAuHuUDQUHY",
        "colab_type": "code",
        "outputId": "4d0838d1-244d-4750-d30d-ad38629bdb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "language_model_learner.model.load_state_dict(torch.load(PATH/'models'/'tw_pretrained_20191030.pkl'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2NF5MPVQZJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "language_model_layer_groups = [\n",
        "  (language_model_learner.model[0].emb, language_model_learner.model[0].input_dp),\n",
        "  *zip(language_model_learner.model[0].rnns, language_model_learner.model[0].hidden_dps),\n",
        "  (language_model_learner.model[1].decoder,language_model_learner.model[1].output_dp)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DorHNVTxQzHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c75d64bf-866d-4cea-9dc3-048b1374f420"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in language_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  Linear(in_features=400, out_features=15484, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx84e4lzQfKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_all(language_model_layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwJlgfs0Pqu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8a48533-0531-4da8-a200-ba47229c68d3"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in language_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0_raw False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0_raw False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0_raw False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  Linear(in_features=400, out_features=15484, bias=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4fOKW0HQjZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unfreeze_all(language_model_layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD1H5FR2QztP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c3fab84-b11b-4c5c-fc84-2c517957564e"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in language_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  Linear(in_features=400, out_features=15484, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNhFEpxJQkyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_upto(language_model_layer_groups, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFVbHoFBQ0gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc51a6e0-c3ce-48c8-af28-f172a42ef81a"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in language_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0_raw False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0_raw False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0_raw True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  Linear(in_features=400, out_features=15484, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVyXP1txQ24t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "f8a5b3a3-a160-4955-fe4b-63ba97b4b220"
      },
      "source": [
        "language_model_learner.fit(3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "train: [5.1576648517309875, tensor(0.2359, device='cuda:0')]\n",
            "valid: [4.239763603608715, tensor(0.3656, device='cuda:0')]\n",
            "1\n",
            "train: [4.090590859108967, tensor(0.3605, device='cuda:0')]\n",
            "valid: [4.014514121368588, tensor(0.3802, device='cuda:0')]\n",
            "2\n",
            "train: [3.9299823531498297, tensor(0.3768, device='cuda:0')]\n",
            "valid: [3.9086641440649115, tensor(0.3863, device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWcoVnxyVYiW",
        "colab_type": "text"
      },
      "source": [
        "exemple for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JngiJHbZQOoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_orig_ids = np.load(CLAS_PATH/'train_orig_ids.npy', allow_pickle=True)\n",
        "val_orig_ids = np.load(CLAS_PATH/'test_orig_ids.npy', allow_pickle=True)\n",
        "\n",
        "trn_orig_labels = np.load(CLAS_PATH/'train_orig_labels.npy', allow_pickle=True)\n",
        "val_orig_labels = np.load(CLAS_PATH/'test_orig_labels.npy', allow_pickle=True)\n",
        "\n",
        "trn_orig_ds = TextClassificationDataset(trn_orig_ids, trn_orig_labels)\n",
        "val_orig_ds = TextClassificationDataset(val_orig_ids, val_orig_labels)\n",
        "\n",
        "trn_orig_sampler = TrainingSampler(trn_orig_ds.x, key=lambda t: len(trn_orig_ds.x[t]), bs=encode_args.batchsize)\n",
        "trn_orig_dl = DataLoader(trn_orig_ds, batch_size=encode_args.batchsize, sampler=trn_orig_sampler, collate_fn=pad_collate)\n",
        "val_orig_sampler = ValidationSampler(val_orig_ds.x, key=lambda t: len(val_orig_ds.x[t]))\n",
        "val_orig_dl = DataLoader(val_orig_ds, batch_size=encode_args.batchsize*2, sampler=val_orig_sampler, collate_fn=pad_collate)\n",
        "db_trn_orig_val_orig = DataBunch(trn_orig_dl, val_orig_dl)\n",
        "\n",
        "sent_enc = SentenceEncoder(lstm_enc, encode_args.bptt)\n",
        "pool_clas = PoolingLinearClassifier(layers=[3*encode_args.emsize, 100, 4], drops=[0.2, 0.1])\n",
        "clas_model = SequentialRNN(sent_enc, pool_clas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "754qgOivViI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbs_clas = [CudaCallback(), TrainEvalCallback(), AvgStatsCallback([accuracy]), Recorder()]\n",
        "trn_orig_learn = Learner(clas_model, db_trn_orig_val_orig, F.cross_entropy, opt_func=adam_opt(), lr=1e-5, cbs=cbs_clas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MoXFScpr_nh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "ec7e8176-94b4-49a2-c7bb-eb2645219b72"
      },
      "source": [
        "trn_orig_learn.model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialRNN(\n",
              "  (0): SentenceEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (emb): Embedding(15484, 400, padding_idx=1)\n",
              "      (emb_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(15484, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): ConnectionWeightDropout(\n",
              "          (module): LSTM(400, 1150, batch_first=True)\n",
              "        )\n",
              "        (1): ConnectionWeightDropout(\n",
              "          (module): LSTM(1150, 1150, batch_first=True)\n",
              "        )\n",
              "        (2): ConnectionWeightDropout(\n",
              "          (module): LSTM(1150, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): ActivationDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): ActivationDropout()\n",
              "        (1): ActivationDropout()\n",
              "        (2): ActivationDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=100, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=100, out_features=4, bias=True)\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS8mvdO5WRf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clas_model_layer_groups = [\n",
        "  (trn_orig_learn.model[0].module.emb, trn_orig_learn.model[0].module.input_dp),\n",
        "  *zip(trn_orig_learn.model[0].module.rnns, trn_orig_learn.model[0].module.hidden_dps),\n",
        "  (trn_orig_learn.model[1].layers[0],trn_orig_learn.model[1].layers[1],trn_orig_learn.model[1].layers[2],trn_orig_learn.model[1].layers[3]),\n",
        "  (trn_orig_learn.model[1].layers[4],trn_orig_learn.model[1].layers[5],trn_orig_learn.model[1].layers[6],trn_orig_learn.model[1].layers[7])\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3aReVDXZUsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31dc9160-f42c-4895-ce9f-deb167a99873"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in clas_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.2, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=1200, out_features=100, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n",
            "layer 6 : \n",
            "function:  BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.1, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=100, out_features=4, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czGF9qerZb__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_all(clas_model_layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvXVC8-EZZgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "066f7540-d28f-40ee-fb70-fc5b9ed22158"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in clas_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.2, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=1200, out_features=100, bias=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n",
            "layer 6 : \n",
            "function:  BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.1, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=100, out_features=4, bias=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOtj93PUZk2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unfreeze_all(clas_model_layer_groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3OLoTXaZZYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "895ec946-e601-4f20-c488-ee017e30ea3d"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in clas_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 True\n",
            "******\n",
            "parameter module.weight_hh_l0 True\n",
            "******\n",
            "parameter module.bias_ih_l0 True\n",
            "******\n",
            "parameter module.bias_hh_l0 True\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.2, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=1200, out_features=100, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n",
            "layer 6 : \n",
            "function:  BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.1, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=100, out_features=4, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv1tEpQ1ZnuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freeze_upto(clas_model_layer_groups, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQG84CLFZZOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ab11358-633b-4b38-9651-0bd6caa60ef5"
      },
      "source": [
        "# go through all parameters\n",
        "i = 0\n",
        "for layer in clas_model_layer_groups:\n",
        "  i += 1\n",
        "  print('layer', i, ': ')\n",
        "  for f in layer:\n",
        "    print('function: ', f)\n",
        "    for name, p in f.named_parameters():\n",
        "      print('parameter', name, p.requires_grad)\n",
        "      print('***'*2)\n",
        "    print('---'*4)\n",
        "  print('==='*8)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 1 : \n",
            "function:  Embedding(15484, 400, padding_idx=1)\n",
            "parameter weight False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 2 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(400, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 3 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 1150, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 4 : \n",
            "function:  ConnectionWeightDropout(\n",
            "  (module): LSTM(1150, 400, batch_first=True)\n",
            ")\n",
            "parameter module.weight_ih_l0 False\n",
            "******\n",
            "parameter module.weight_hh_l0 False\n",
            "******\n",
            "parameter module.bias_ih_l0 False\n",
            "******\n",
            "parameter module.bias_hh_l0 False\n",
            "******\n",
            "------------\n",
            "function:  ActivationDropout()\n",
            "------------\n",
            "========================\n",
            "layer 5 : \n",
            "function:  BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.2, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=1200, out_features=100, bias=True)\n",
            "parameter weight False\n",
            "******\n",
            "parameter bias False\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n",
            "layer 6 : \n",
            "function:  BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  Dropout(p=0.1, inplace=False)\n",
            "------------\n",
            "function:  Linear(in_features=100, out_features=4, bias=True)\n",
            "parameter weight True\n",
            "******\n",
            "parameter bias True\n",
            "******\n",
            "------------\n",
            "function:  ReLU(inplace=True)\n",
            "------------\n",
            "========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXt9arGQZ0Nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "5acf9cd9-90dc-4dce-f86e-3c5df17ddab3"
      },
      "source": [
        "trn_orig_learn.fit(3)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "train: [1.4411440886092823, tensor(0.2559, device='cuda:0')]\n",
            "valid: [1.3730971323551464, tensor(0.3570, device='cuda:0')]\n",
            "1\n",
            "train: [1.4609557924355527, tensor(0.2270, device='cuda:0')]\n",
            "valid: [1.3866414309920825, tensor(0.2937, device='cuda:0')]\n",
            "2\n",
            "train: [1.4449442968170438, tensor(0.2470, device='cuda:0')]\n",
            "valid: [1.4008582878478886, tensor(0.2898, device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzdb6Wjxsf9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
